import streamlit as st
import pandas as pd
import numpy as np
import joblib
from pathlib import Path
import plotly.express as px
import plotly.graph_objects as go
import matplotlib.pyplot as plt

from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

# SHAP √© opcional ‚Äì tentamos importar
try:
    import shap
    SHAP_AVAILABLE = True
except ImportError:
    SHAP_AVAILABLE = False

# ======= CONFIG GERAL =======
st.set_page_config(
    page_title="EmpresaX ‚Äî Predi√ß√£o de Custos",
    page_icon="üìà",
    layout="wide"
)

st.title("üìà EmpresaX ‚Äî Dashboard de Predi√ß√£o de Custos (MVP+)")


# ======================================================================
# =========================== PAR√ÇMETROS ================================
# ======================================================================

DEFAULT_MODEL_NAME = "model_RF_cost_per_unit_imp_20251113_122506.joblib"
DEFAULT_MODEL_DIR  = Path("/home/rusch/√Årea de trabalho/Projeto_Whirpool/Data_Science_Projects/eda/models")
DEFAULT_MODEL_PATH = (DEFAULT_MODEL_DIR / DEFAULT_MODEL_NAME).as_posix()

TARGET_DEFAULT = "cost_per_unit_imp"  # alvo padr√£o


# ======================================================================
# ===================== FUN√á√ïES AUXILIARES =============================
# ======================================================================

def robust_scale(series: pd.Series) -> pd.Series:
    """Robust Z-score: (x - mediana) / (1.4826 * MAD)."""
    med = series.median()
    mad = np.median(np.abs(series - med))
    if mad == 0:
        mad = series.std() if series.std() > 0 else 1.0
    return (series - med) / (1.4826 * mad)


def add_robust_features(df: pd.DataFrame) -> pd.DataFrame:
    """
    Gera colunas *_robust de forma estatisticamente robusta,
    se as colunas base existirem.
    """
    df = df.copy()
    if "kwh_per_unit_imp" in df.columns:
        df["kwh_per_unit_imp_robust"] = robust_scale(df["kwh_per_unit_imp"])
    if "cost_per_unit_imp" in df.columns:
        df["cost_per_unit_imp_robust"] = robust_scale(df["cost_per_unit_imp"])
    if "fx_effect_ratio_imp" in df.columns:
        df["fx_effect_ratio_imp_robust"] = robust_scale(df["fx_effect_ratio_imp"])
    return df


def add_robust_if_missing_simple(df: pd.DataFrame) -> pd.DataFrame:
    """
    Vers√£o simples: se *_robust n√£o existir, cria como c√≥pia da coluna base.
    √ötil como fallback para compatibilidade com o modelo.
    """
    df = df.copy()
    mapping = {
        "kwh_per_unit_imp_robust": "kwh_per_unit_imp",
        "cost_per_unit_imp_robust": "cost_per_unit_imp",
        "fx_effect_ratio_imp_robust": "fx_effect_ratio_imp",
    }
    for new_col, base_col in mapping.items():
        if new_col not in df.columns and base_col in df.columns:
            df[new_col] = df[base_col]
    return df


def align_with_model_features(df: pd.DataFrame, model, target: str | None):
    """
    - Garante colunas robustas
    - Separa y_true (se alvo existir)
    - Converte tipos b√°sicos
    - Reordena colunas segundo feature_names_in_ do modelo
    """
    df = add_robust_features(df)          # robusto "bonito"
    df = add_robust_if_missing_simple(df) # garante presen√ßa, se faltar

    y_true = None
    if target and target in df.columns:
        y_true = df[target].copy()
        X = df.drop(columns=[target])
    else:
        X = df.copy()

    # Convers√µes de tipos comuns
    if "site_code" in X.columns:
        X["site_code"] = X["site_code"].astype(str)
    if "m" in X.columns:
        X["m"] = pd.to_numeric(X["m"], errors="coerce").astype("Int64")
    if "y" in X.columns:
        X["y"] = pd.to_numeric(X["y"], errors="coerce").astype("Int64")

    # Usa feature_names_in_ como "verdade"
    feat_in = getattr(model, "feature_names_in_", None)
    extra = []
    if isinstance(feat_in, (list, tuple, np.ndarray, pd.Index)):
        feat_in = list(feat_in)

        missing = [c for c in feat_in if c not in X.columns]
        extra = [c for c in X.columns if c not in feat_in]

        # Tratamento especial: se o modelo espera 'date_key' e ela n√£o est√° no CSV,
        # criamos uma coluna constante (0) s√≥ para compatibilizar o deploy.
        if "date_key" in missing:
            # voc√™ pode escolher outra conven√ß√£o aqui, por ex. 0 ou um √≠ndice sequencial
            X["date_key"] = 0
            missing = [c for c in missing if c != "date_key"]

        # Se ainda restarem colunas faltando, a√≠ sim damos erro
        if missing:
            raise ValueError(f"Faltam colunas esperadas pelo modelo: {missing}")

        # Reordena X exatamente na ordem de treino
        X = X[feat_in]

    return X, y_true, extra


def compute_regression_metrics(y_true: np.ndarray, y_pred: np.ndarray) -> dict:
    mae = mean_absolute_error(y_true, y_pred)
    mse = mean_squared_error(y_true, y_pred)
    rmse = np.sqrt(mse)
    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100 if np.all(y_true != 0) else np.nan
    r2 = r2_score(y_true, y_pred)
    return {"MAE": mae, "MSE": mse, "RMSE": rmse, "MAPE": mape, "R2": r2}


def get_final_estimator(model):
    """
    Retorna o √∫ltimo estimador do Pipeline (se for um Pipeline),
    sen√£o retorna o pr√≥prio modelo.
    """
    # Pipeline com named_steps
    if hasattr(model, "named_steps"):
        return list(model.named_steps.values())[-1]
    # Pipeline com steps (lista de (nome, obj))
    if hasattr(model, "steps"):
        return model.steps[-1][1]
    # Modelo "simples"
    return model


def get_feature_names_from_pipeline(pipeline):
    """
    Extrai nomes das features ap√≥s o ColumnTransformer/OneHotEncoder/etc.
    """
    if not hasattr(pipeline, "named_steps"):
        return getattr(pipeline, "feature_names_in_", None)

    # procura um ColumnTransformer dentro do pipeline
    ct = None
    for _, step in pipeline.named_steps.items():
        if hasattr(step, "transformers_"):
            ct = step
            break

    if ct is None:
        return getattr(pipeline, "feature_names_in_", None)

    output_features = []
    for name, transformer, cols in ct.transformers_:
        if name == "remainder" and transformer == "drop":
            continue

        if hasattr(transformer, "get_feature_names_out"):
            new_feats = transformer.get_feature_names_out(cols)
            output_features.extend(new_feats)
        else:
            output_features.extend(cols)

    return output_features

def get_preprocess_from_pipeline(pipeline):
    """
    Retorna o ColumnTransformer (ou etapa de preprocessamento) de dentro do Pipeline,
    se existir. Caso contr√°rio, retorna None.
    """
    if not hasattr(pipeline, "named_steps"):
        return None

    for _, step in pipeline.named_steps.items():
        # ColumnTransformer tem atributo transformers_
        if hasattr(step, "transformers_"):
            return step

    return None


@st.cache_resource
def load_model(path: str):
    return joblib.load(path)

# ======================================================================
# =========================== SIDEBAR ==================================
# ======================================================================

st.sidebar.header("Configura√ß√µes gerais")

model_path = st.sidebar.text_input("Caminho do modelo (.joblib)", value=DEFAULT_MODEL_PATH)
target_name = st.sidebar.text_input("Nome da coluna alvo (TARGET)", value=TARGET_DEFAULT)

uploaded = st.sidebar.file_uploader("Suba um CSV com as features", type=["csv"])
show_preview = st.sidebar.checkbox("Mostrar preview do CSV", value=True)


# ======================================================================
# ===================== CARREGAR MODELO ================================
# ======================================================================

try:
    model = load_model(model_path)
    st.sidebar.success(f"Modelo carregado: {type(model).__name__}")
except Exception as e:
    st.sidebar.error(f"Falha ao carregar modelo: {e}")
    st.stop()


# ======================================================================
# ===================== ABAS PRINCIPAIS ================================
# ======================================================================

tab_upload, tab_predict, tab_graphs, tab_features, tab_config = st.tabs(
    ["üìÅ Upload & Dados", "üìä Predi√ß√£o & M√©tricas", "üìà An√°lise Gr√°fica", "üß¨ Import√¢ncia das Features", "‚öôÔ∏è Configura√ß√£o/Log"]
)

# Container compartilhado entre abas
df_raw = None
X = None
y_true = None
y_pred = None
pred_df = None
extra_cols = []

# ======================================================================
# ========================== ABA 1 ‚Äî UPLOAD =============================
# ======================================================================

with tab_upload:
    st.subheader("üìÅ Upload & Explora√ß√£o de Dados")

    if uploaded is None:
        st.info("Envie um arquivo CSV pela barra lateral para come√ßar.")
    else:
        try:
            uploaded.seek(0)  # <- rebobina o arquivo para o in√≠cio
            df_raw = pd.read_csv(uploaded)
            st.success(f"Arquivo carregado com sucesso. Formato: {df_raw.shape[0]} linhas √ó {df_raw.shape[1]} colunas.")

            if show_preview:
                st.markdown("#### Preview das primeiras linhas")
                st.dataframe(df_raw.head())

            st.markdown("#### Informa√ß√µes gerais do DataFrame")
            st.write(df_raw.describe(include="all").transpose())

        except Exception as e:
            st.error(f"Erro ao ler o CSV: {e}")


# ======================================================================
# ===================== PROCESSAMENTO COMUM ============================
# ======================================================================

if uploaded is not None:
    try:
        uploaded.seek(0)  # <- rebobina o arquivo para o in√≠cio
        df_raw = pd.read_csv(uploaded)

        X, y_true, extra_cols = align_with_model_features(
            df_raw, model, target_name if target_name else None
        )
        y_pred = model.predict(X)
        pred_df = X.copy()
        pred_df["prediction"] = y_pred
        if y_true is not None:
            pred_df["y_true"] = y_true.values

    except Exception as e:
        with tab_predict:
            st.error("Falha ao preparar dados para predi√ß√£o.")
            st.write("Mensagem completa do erro:")
            st.exception(e)

# ======================================================================
# ===================== ABA 2 ‚Äî PREDI√á√ÉO & M√âTRICAS ====================
# ======================================================================

with tab_predict:
    st.subheader("üìä Predi√ß√£o & M√©tricas")

    st.write("DEBUG ‚Äî uploaded is None?", uploaded is None)
    st.write("DEBUG ‚Äî pred_df is None?", pred_df is None)

    if uploaded is None or pred_df is None:
        st.info("Suba um CSV e garanta que o alinhamento de features esteja OK na aba anterior.")
    else:
        # Filtros simples
        if "site_code" in pred_df.columns:
            sites = ["(Todos)"] + sorted(pred_df["site_code"].astype(str).unique().tolist())
            site_sel = st.selectbox("Filtrar por site_code", sites)
            df_view = pred_df.copy()
            if site_sel != "(Todos)":
                df_view = df_view[df_view["site_code"].astype(str) == site_sel]
        else:
            df_view = pred_df.copy()

        st.markdown("#### Amostra das predi√ß√µes")
        st.dataframe(df_view.head(50))

        # M√©tricas se houver y_true
        if "y_true" in df_view.columns:
            metrics = compute_regression_metrics(df_view["y_true"], df_view["prediction"])
            c1, c2, c3, c4, c5 = st.columns(5)

            # MAE
            with c1:
                st.markdown(
                    """
                    <span title="MAE (Mean Absolute Error) √© o erro absoluto m√©dio entre o valor real (y_true) e o previsto (prediction), na mesma unidade do alvo. Quanto menor, melhor.">
                    MAE ‚ìò
                    </span>
                    """,
                    unsafe_allow_html=True,
                )
                st.metric(label="", value=f"{metrics['MAE']:.3f}")

            # RMSE
            with c2:
                st.markdown(
                    """
                    <span title="RMSE (Root Mean Squared Error) √© a raiz quadrada do erro quadr√°tico m√©dio. Penaliza mais fortemente erros grandes e tamb√©m est√° na mesma unidade da vari√°vel alvo.">
                        RMSE ‚ìò
                    </span>
                    """,
                    unsafe_allow_html=True,
                )
                st.metric(label="", value=f"{metrics['RMSE']:.3f}")

            # MAPE
            with c3:
                mape_str = f"{metrics['MAPE']:.2f}" if not np.isnan(metrics["MAPE"]) else "N/A"
                st.markdown(
                    """
                    <span title="MAPE (Mean Absolute Percentage Error) √© o erro percentual m√©dio. Indica, em m√©dia, quanto % o valor previsto se afasta do valor real. Valores baixos indicam boa performance.">
                        MAPE (%) ‚ìò
                    </span>
                    """,
                    unsafe_allow_html=True,
                )
                st.metric(label="", value=mape_str)

            # R¬≤
            with c4:
                st.markdown(
                    """
                    <span title="R¬≤ (coeficiente de determina√ß√£o) mede a propor√ß√£o da variabilidade dos dados explicada pelo modelo. Valores pr√≥ximos de 1 indicam excelente capacidade explicativa.">
                        R¬≤ ‚ìò
                    </span>
                    """,
                    unsafe_allow_html=True,
                )
                st.metric(label="", value=f"{metrics['R2']:.3f}")

            # MSE
            with c5:
                st.markdown(
                    """
                    <span title="MSE (Mean Squared Error) √© o erro quadr√°tico m√©dio. Fica em unidades ao quadrado e por isso os valores num√©ricos tendem a ser grandes. Deve ser interpretado em rela√ß√£o √† escala da vari√°vel alvo.">
                        MSE ‚ìò
                    </span>
                    """,
                    unsafe_allow_html=True,
                )
                st.metric(label="", value=f"{metrics['MSE']:.3f}")

            st.markdown(
                """
                **Interpreta√ß√£o das colunas e m√©tricas**

                - A coluna **`prediction`** representa o valor **previsto** da vari√°vel-alvo 
                  (`cost_per_unit_imp` - custo unit√°rio do produto) pelo modelo de Machine Learning, para cada linha do CSV.
                - A coluna **`y_true`** (quando existe no arquivo) √© o valor **real observado** no hist√≥rico de dados (o `cost_per_unit_imp`
                  calculado por meio da ETL e da EDA).
                - O **res√≠duo** de cada observa√ß√£o √© definido como:

                  > res√≠duo = y_true - prediction

                - **MAE (Mean Absolute Error)**: erro absoluto m√©dio em **unidades monet√°rias**.
                  Quanto menor, melhor.
                - **RMSE (Root Mean Squared Error)**: raiz do erro quadr√°tico m√©dio.
                  Penaliza mais fortemente erros grandes. Tamb√©m est√° em unidades monet√°rias.
                - **MSE (Mean Squared Error)**: erro quadr√°tico m√©dio. Fica em unidades ao quadrado
                  e, por isso, costuma ter valor num√©rico grande ‚Äî ele deve ser interpretado em rela√ß√£o
                  √† escala da vari√°vel alvo.
                - **MAPE (%)**: erro percentual m√©dio. Indica, em m√©dia, qual o desvio percentual
                  entre o valor real e o previsto.
                - **R¬≤ (coeficiente de determina√ß√£o)**: mede quanta da variabilidade dos dados
                  √© explicada pelo modelo. Valores pr√≥ximos de 1 indicam excelente capacidade
                  explicativa.

                > Observa√ß√£o: como os custos unit√°rios t√≠picos est√£o na faixa de centenas (por exemplo,
                > 700‚Äì1100), um RMSE da ordem de dezenas (ex.: ~20) corresponde a um erro relativo
                > baixo (cerca de 1‚Äì3%), o que √© considerado um desempenho muito bom.
                """
            )

        else:
            st.info("Nenhuma coluna alvo detectada, m√©tricas num√©ricas indispon√≠veis.")

        # Download das predi√ß√µes
        @st.cache_data
        def convert_df_to_csv(df):
            return df.to_csv(index=False).encode("utf-8")

        csv_bytes = convert_df_to_csv(pred_df)
        st.download_button(
            "üíæ Baixar predi√ß√µes (CSV)",
            data=csv_bytes,
            file_name="predictions_whirlpool.csv",
            mime="text/csv"
        )


# ======================================================================
# ===================== ABA 3 ‚Äî AN√ÅLISE GR√ÅFICA =======================
# ======================================================================

with tab_graphs:
    st.subheader("üìà An√°lise Gr√°fica")

    if uploaded is None or pred_df is None or "y_true" not in pred_df.columns:
        st.info("√â necess√°rio ter valores reais (coluna alvo) no CSV para an√°lise gr√°fica completa.")
    else:
        # ===================== Filtro por site_code =====================
        df_plot = pred_df.copy()

        if "site_code" in df_plot.columns:
            sites = ["(Todos)"] + sorted(df_plot["site_code"].astype(str).unique().tolist())
            site_sel_graphs = st.selectbox(
                "Filtrar gr√°ficos por site_code",
                sites,
                key="site_filter_graphs",
            )
            if site_sel_graphs != "(Todos)":
                df_plot = df_plot[df_plot["site_code"].astype(str) == site_sel_graphs]

        if df_plot.empty:
            st.warning("Nenhuma linha dispon√≠vel para o site selecionado.")
            st.stop()

        # ===================== Real vs Previsto =====================
        st.markdown(
            """
            <span title="Cada ponto representa uma observa√ß√£o do dataset (ou do site filtrado). 
            Se o modelo estiver bem calibrado, os pontos devem ficar pr√≥ximos da linha de 45¬∞ (linha y = x). 
            Grandes desvios dessa linha indicam previs√µes com erro maior.">
                <big>Figura 1: Real vs. Previsto ‚ìò</big>
            </span>
            """,
            unsafe_allow_html=True,
        )

        y_true = df_plot["y_true"]
        y_pred = df_plot["prediction"]

        min_val = float(min(y_true.min(), y_pred.min()))
        max_val = float(max(y_true.max(), y_pred.max()))

        fig_real_pred = go.Figure()

        fig_real_pred.add_trace(
            go.Scatter(
                x=y_true,
                y=y_pred,
                mode="markers",
                name="Observa√ß√µes",
                opacity=0.5,
                marker=dict(color='cyan', size=6),
                hovertemplate="Real: %{x:.2f}<br>Previsto: %{y:.2f}<extra></extra>",
            )
        )

        fig_real_pred.add_trace(
            go.Scatter(
                x=[min_val, max_val],
                y=[min_val, max_val],
                mode="lines",
                name="Linha y = x",
                line=dict(color='red', dash="dash", width=2),
                hoverinfo="skip",
            )
        )

        fig_real_pred.update_layout(
            xaxis_title="Real",
            yaxis_title="Previsto",
            showlegend=True,
            margin=dict(l=60, r=20, t=20, b=40),
        )

        st.plotly_chart(fig_real_pred, use_container_width=True)

        # ===================== Res√≠duos =====================
        residuals = y_true - y_pred

        col1, col2 = st.columns(2)

        with col1:
            st.markdown(
                """
                <span title="Mostra a distribui√ß√£o dos valores de (y_true - prediction) para o conjunto filtrado. 
                Idealmente, os res√≠duos devem estar centrados em zero, sem assimetria forte e sem caudas muito pesadas.">
                    <big>Figura 2: Histograma dos res√≠duos ‚ìò</big>
                </span>
                """,
                unsafe_allow_html=True,
            )

            fig_hist = px.histogram(
                x=residuals,
                nbins=30,
                labels={"x": "Res√≠duo (y_true - prediction)", "y": "Frequ√™ncia"},
            )
            fig_hist.update_layout(
                margin=dict(l=60, r=20, t=20, b=40),
            )
            st.plotly_chart(fig_hist, use_container_width=True)

        with col2:
            st.markdown(
                """
                <span title="Cada ponto mostra o erro (y_true - prediction) em fun√ß√£o do valor previsto, 
                para o conjunto filtrado. √â desej√°vel que os pontos estejam distribu√≠dos aleatoriamente 
                em torno de zero.">
                    <big>Figura 3: Res√≠duo vs. Previsto ‚ìò</big>
                </span>
                """,
                unsafe_allow_html=True,
            )

            fig_res_vs_pred = px.scatter(
                x=y_pred,
                y=residuals,
                labels={"x": "Previsto", "y": "Res√≠duo (y_true - prediction)"},
                opacity=0.5,
            )
            fig_res_vs_pred.add_hline(
                y=0, 
                line=dict(color="red", dash="dash", width=2), 
                annotation_text="res√≠duo = 0"
            )

            fig_res_vs_pred.update_layout(
                margin=dict(l=60, r=20, t=20, b=40),
            )
            st.plotly_chart(fig_res_vs_pred, use_container_width=True)

        # (mant√©m o texto interpretativo igual ‚Äî j√° vale "condicionado ao filtro")


# ======================================================================
# ===================== ABA 4 ‚Äî FEATURE IMPORTANCE =====================
# ======================================================================

with tab_features:
    st.subheader("üß¨ Import√¢ncia das Features")

    if uploaded is None or pred_df is None:
        st.info("Carregue dados e gere predi√ß√µes para visualizar a import√¢ncia das features.")
    else:
        # ===================== Filtro por site_code =====================
        df_feat = pred_df.copy()

        if "site_code" in df_feat.columns:
            sites = ["(Todos)"] + sorted(df_feat["site_code"].astype(str).unique().tolist())
            site_sel_feat = st.selectbox(
                "Filtrar explicabilidade por site_code",
                sites,
                key="site_filter_features",
            )
            if site_sel_feat != "(Todos)":
                df_feat = df_feat[df_feat["site_code"].astype(str) == site_sel_feat]

        if df_feat.empty:
            st.warning("Nenhuma linha dispon√≠vel para o site selecionado.")
            st.stop()

        final_model = get_final_estimator(model)


        # ---------------- Feature importances ----------------
        if hasattr(final_model, "feature_importances_"):
            importances = np.asarray(final_model.feature_importances_)

            feats = get_feature_names_from_pipeline(model)
            if feats is None:
                feats = df_feat.columns.tolist()
            feats = list(feats)

            if len(feats) != len(importances):
                st.error(
                    f"N√∫mero de features ({len(feats)}) n√£o corresponde ao n√∫mero de "
                    f"import√¢ncias ({len(importances)})."
                )
            else:
                imp_df = pd.DataFrame({"feature": feats, "importance": importances})
                imp_df["importance_norm"] = imp_df["importance"] / imp_df["importance"].sum()

                top10 = imp_df.sort_values("importance", ascending=False).head(10)
                top10 = top10.sort_values("importance_norm", ascending=True)

                st.markdown(
                    """
                    #### Import√¢ncia das Features (RandomForest ‚Äì Global) ‚ìò
                    <span title="Import√¢ncias estimadas pela Random Forest a partir de todo o conjunto de treinamento. 
                    N√£o dependem do filtro de site_code; representam o efeito m√©dio global das vari√°veis.">
                        <small>Passe o mouse sobre o t√≠tulo ou sobre as barras para ver os detalhes.</small>
                    </span>
                    """,
                    unsafe_allow_html=True,
                )

                fig_imp = px.bar(
                    top10,
                    x="importance_norm",
                    y="feature",
                    orientation="h",
                    labels={
                        "importance_norm": "Import√¢ncia normalizada",
                        "feature": "Feature",
                    },
                    hover_data={
                        "importance_norm": ":.2%",
                        "importance": ":.4f",
                    },
                )
                fig_imp.update_layout(
                    margin=dict(l=140, r=40, t=40, b=40),
                    yaxis_title=None,
                )

                st.plotly_chart(fig_imp, use_container_width=True)

        # ---------------- SHAP (explicabilidade) ----------------
        st.markdown("#### SHAP values (explicabilidade local/global por site)")

        if not SHAP_AVAILABLE:
            st.warning("Pacote `shap` n√£o est√° instalado. Instale com `pip install shap` para ativar.")
        else:
            try:
                # Seleciona as linhas de X que correspondem ao filtro aplicado em df_feat
                idxs = df_feat.index
                X_shap = X.loc[idxs].copy()

                MAX_SHAP_SAMPLES = 500  # pode ajustar esse limite
                if len(X_shap) > MAX_SHAP_SAMPLES:
                    X_shap = X_shap.sample(MAX_SHAP_SAMPLES, random_state=42)

                # 1) Aplica o mesmo preprocessamento do Pipeline (ColumnTransformer)
                preprocess = get_preprocess_from_pipeline(model)
                if preprocess is not None:
                    X_proc = preprocess.transform(X_shap)
                else:
                    X_proc = X_shap.values

                if hasattr(X_proc, "toarray"):
                    X_proc = X_proc.toarray()

                # 2) Nomes das features ap√≥s preprocess
                feat_names = get_feature_names_from_pipeline(model)
                if feat_names is None:
                    feat_names = [f"f_{i}" for i in range(X_proc.shape[1])]

                # 3) TreeExplainer no estimador final (RandomForest)
                explainer = shap.TreeExplainer(final_model)
                shap_values = explainer.shap_values(X_proc)

                if isinstance(shap_values, list):
                    shap_arr = np.array(shap_values[0])
                else:
                    shap_arr = np.array(shap_values)

                # ================== SHAP GLOBAL (Plotly) ==================
                mean_abs_shap = np.mean(np.abs(shap_arr), axis=0)
                shap_global_df = pd.DataFrame({
                    "feature": feat_names,
                    "mean_abs_shap": mean_abs_shap
                })
                shap_global_df["mean_abs_shap_norm"] = shap_global_df["mean_abs_shap"] / shap_global_df["mean_abs_shap"].sum()

                topN = shap_global_df.sort_values("mean_abs_shap", ascending=False).head(10)
                topN = topN.sort_values("mean_abs_shap_norm", ascending=True)

                st.markdown(
                    """
                    ##### Import√¢ncia global SHAP (Top 10 ‚Äì condicionado ao filtro de site) ‚ìò
                    <span title="Mostra as 10 vari√°veis com maior impacto m√©dio absoluto nas predi√ß√µes, segundo os valores SHAP, considerando apenas as observa√ß√µes do subconjunto filtrado (site_code selecionado).">
                        <small>Passe o mouse sobre as barras para detalhes.</small>
                    </span>
                    """,
                    unsafe_allow_html=True,
                )

                fig_shap_global = px.bar(
                    topN,
                    x="mean_abs_shap_norm",
                    y="feature",
                    orientation="h",
                    labels={
                        "mean_abs_shap_norm": "Import√¢ncia SHAP normalizada",
                        "feature": "Feature",
                    },
                    hover_data={
                        "mean_abs_shap_norm": ":.2%",
                        "mean_abs_shap": ":.4f",
                    },
                )
                fig_shap_global.update_layout(
                    margin=dict(l=140, r=40, t=40, b=40),
                    yaxis_title=None,
                )

                st.plotly_chart(fig_shap_global, use_container_width=True)

                # ================== SHAP LOCAL (uma observa√ß√£o) ==================
                st.markdown("##### Explicabilidade local (uma observa√ß√£o do subconjunto filtrado)")

                n_rows = X_proc.shape[0]
                idx_local = st.slider(
                    "Selecione o √≠ndice da observa√ß√£o (ap√≥s filtro) para an√°lise local",
                    min_value=0,
                    max_value=n_rows - 1,
                    value=0,
                )

                shap_local = shap_arr[idx_local]
                x_local = X_proc[idx_local]

                local_df = pd.DataFrame({
                    "feature": feat_names,
                    "shap_value": shap_local,
                    "abs_shap": np.abs(shap_local),
                    "feature_value": x_local,
                }).sort_values("abs_shap", ascending=True).tail(10)

                fig_shap_local = px.bar(
                    local_df,
                    x="shap_value",
                    y="feature",
                    orientation="h",
                    labels={
                        "shap_value": "Contribui√ß√£o SHAP (impacto na predi√ß√£o)",
                        "feature": "Feature",
                    },
                    hover_data={
                        "feature_value": True,
                        "abs_shap": ":.4f",
                    },
                )
                fig_shap_local.update_layout(
                    margin=dict(l=180, r=40, t=40, b=40),
                    yaxis_title=None,
                )

                st.plotly_chart(fig_shap_local, use_container_width=True)

                st.markdown(
                    """
                    **Leitura dos gr√°ficos SHAP condicionados ao site**

                    - O gr√°fico **global SHAP** considera apenas as observa√ß√µes do subconjunto filtrado
                      (por exemplo, um `site_code` espec√≠fico) e mostra quais vari√°veis mais
                      contribuem para o comportamento daquele site.
                    - O gr√°fico **local SHAP** mostra, para uma linha espec√≠fica desse subconjunto,
                      quais features empurram a predi√ß√£o para cima (valor SHAP positivo) ou para baixo
                      (valor SHAP negativo), e em que magnitude.
                    """
                )

            except Exception as e:
                st.error(f"N√£o foi poss√≠vel calcular/plotar SHAP: {e}")



# ======================================================================
# ===================== ABA 5 ‚Äî CONFIG / LOG ===========================
# ======================================================================

with tab_config:
    st.subheader("‚öôÔ∏è Configura√ß√£o e Log")

    st.markdown("#### Caminhos e par√¢metros atuais")
    st.write(f"**Modelo:** `{model_path}`")
    st.write(f"**TARGET:** `{target_name}`")
    st.write(f"**DEFAULT_MODEL_PATH:** `{DEFAULT_MODEL_PATH}`")

    if uploaded is not None:
        st.markdown("#### Colunas do CSV enviado")
        st.write(list(df_raw.columns))

        if extra_cols:
            st.markdown("#### Colunas extras ignoradas pelo modelo")
            st.write(extra_cols)
        else:
            st.markdown("#### Nenhuma coluna extra detectada (todas usadas ou esperadas pelo modelo).")
    else:
        st.info("Nenhum CSV carregado ainda.")